Архитектура и Инженерное Проектирование BioLight: Комплексное Исследование Систем Анализа Физиологических ДанныхАннотацияНастоящий отчет представляет собой детальное техническое руководство и архитектурное обоснование для разработки BioLight — минимально жизнеспособного продукта (MVP), предназначенного для углубленного анализа физиологических показателей спортсменов. Документ охватывает полный спектр инженерных задач: от проектирования схем баз данных временных рядов на базе PostgreSQL и TimescaleDB до реализации сложных алгоритмических моделей (W'Balance, Critical Power) и интеграции с экосистемами Garmin и Strava. Особое внимание уделяется стратегиям хранения данных с использованием паттернов Slowly Changing Dimensions (SCD), архитектуре реального времени на базе протокола MQTT и методологиям валидации алгоритмов с использованием открытых датасетов, таких как GoldenCheetah OpenData. Цель отчета — предоставить исчерпывающую техническую спецификацию, позволяющую команде разработчиков создать масштабируемую, производительную и научно обоснованную платформу.1. Фундаментальная Архитектура Баз Данных: PostgreSQL и TimescaleDBВыбор системы управления базами данных (СУБД) для BioLight является критическим решением, определяющим способность системы масштабироваться от тысяч до миллиардов записей телеметрии. Традиционные реляционные базы данных, хотя и обеспечивают надежность (ACID), часто не справляются с нагрузкой записи, характерной для IoT-сенсоров высокой частоты (1-25 Гц). С другой стороны, специализированные NoSQL решения для временных рядов часто требуют внедрения нового стека технологий и усложняют выполнение реляционных запросов (например, объединение данных телеметрии с профилем пользователя).Анализ показывает, что гибридный подход с использованием PostgreSQL с расширением TimescaleDB является оптимальным архитектурным выбором. Это решение позволяет объединить мощь реляционной модели для метаданных (спортсмены, планы тренировок) и эффективность колоночного хранения для метрик сенсоров в единой системе.1.1. Стратегия Гипертаблиц и Физическое ПартиционированиеЦентральным элементом архитектуры данных BioLight является концепция Гипертаблицы (Hypertable), предоставляемая TimescaleDB. Гипертаблица представляет собой абстракцию над стандартными таблицами PostgreSQL, которая автоматически партиционирует данные по времени (и опционально по пространству/идентификатору устройства) на множество физических таблиц, называемых "чанками" (chunks).Логическая и Физическая Структура ДанныхВ отличие от традиционного подхода, где разработчик должен вручную управлять партициями, TimescaleDB берет эту задачу на себя. Для системы BioLight рекомендуется следующая структура:Логический Уровень: Приложение взаимодействует с единой виртуальной таблицей sensor_telemetry. Это упрощает написание SQL-запросов, так как нет необходимости указывать конкретные партиции в конструкции WHERE.Физический Уровень (Чанки): Данные физически распределяются по чанкам на основе временного интервала. Для телеметрии высокой частоты рекомендуется настройка chunk_time_interval, равная 1 неделе или 1 месяцу, в зависимости от объема данных. Это гарантирует, что активный чанк (hot data), в который идет запись, помещается в оперативную память для максимальной производительности индексов B-tree.Оптимизация Хранения:Для данных сенсоров (RAW), которые после записи редко изменяются, критически важно использовать механизмы сжатия. Данные в чанках, которые "остыли" (например, старше 30 дней), должны конвертироваться из строчного формата (Row-store/Heap), оптимизированного для транзакций, в колоночный формат (Columnar), оптимизированный для аналитики. Это позволяет достичь коэффициента сжатия 90-95%.11.2. Схема Данных Телеметрии (Raw Data Schema)Разработка схемы для sensor_telemetry требует баланса между нормализацией и производительностью. Использование схемы "Entity-Attribute-Value" (EAV) категорически не рекомендуется для основного хранилища из-за низкой производительности агрегаций. Вместо этого предлагается умеренно "широкая" (wide) таблица с типизированными колонками для стандартных метрик и полем JSONB для расширяемости.Таблица 1. Спецификация схемы sensor_telemetryКолонкаТип ДанныхОписание и ОбоснованиеtimeTIMESTAMPTZОсновной ключ партиционирования. Обязателен индекс.athlete_idUUIDВнешний ключ на профиль атлета. Вторичный ключ партиционирования (опционально).activity_idBIGINTСвязь с метаданными тренировки. Используется для сегментации при сжатии.powerSMALLINTМощность в Ваттах. Используем SMALLINT для экономии места (0-32767 Вт достаточно).heart_rateSMALLINTЧастота сердечных сокращений (BPM). NULL если датчик отсутствует.cadenceSMALLINTОбороты в минуту (RPM).speedREALСкорость в м/с (стандарт SI). Тип REAL (float4) достаточен для точности GPS.elevationREALВысота над уровнем моря в метрах.distanceREALНакопленная дистанция в метрах.developer_dataJSONBХранилище для нестандартных метрик (Stryd Power, Garmin Running Dynamics, SmO2), позволяющее добавлять новые типы сенсоров без миграции схемы.SQL-реализация с оптимизациями:SQL-- Активация расширения
CREATE EXTENSION IF NOT EXISTS timescaledb;

-- Создание основной таблицы фактов
CREATE TABLE sensor_telemetry (
    time            TIMESTAMPTZ NOT NULL,
    athlete_id      UUID NOT NULL,
    activity_id     BIGINT NOT NULL,
    power           SMALLINT,
    heart_rate      SMALLINT,
    cadence         SMALLINT,
    speed           REAL,
    elevation       REAL,
    distance        REAL,
    developer_data  JSONB,
    -- Композитный первичный ключ для обеспечения уникальности временной метки в рамках активности
    PRIMARY KEY (time, athlete_id, activity_id)
);

-- Преобразование в гипертаблицу с интервалом чанка 7 дней
SELECT create_hypertable('sensor_telemetry', 'time', chunk_time_interval => INTERVAL '7 days');

-- Настройка компрессии
ALTER TABLE sensor_telemetry SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'activity_id', 
    timescaledb.compress_orderby = 'time DESC'
);

-- Политика автоматического сжатия данных старше 30 дней
SELECT add_compression_policy('sensor_telemetry', INTERVAL '30 days');
Анализ выбора типов данных:Использование SMALLINT вместо INTEGER для полей power и heart_rate позволяет сократить объем хранения на 2 байта на строку. Учитывая миллионы строк, это гигабайты экономии. Поле developer_data типа JSONB обеспечивает гибкость: если новый датчик (например, глюкометр непрерывного действия) начнет передавать данные, их можно сохранить без изменения схемы БД ALTER TABLE. Индексы GIN на поле JSONB позволят эффективно запрашивать даже эти неструктурированные данные.31.3. Непрерывные Агрегаты (Continuous Aggregates)Для построения графиков производительности за длительные периоды (месяцы, годы) запросы к сырым данным (sensor_telemetry) будут слишком медленными. TimescaleDB предлагает механизм Continuous Aggregates — материализованных представлений, которые обновляются автоматически в фоновом режиме по мере поступления новых данных.Это решает проблему "тяжелых" дашбордов. Вместо сканирования миллионов строк секундной записи для отображения "средней мощности за год", система обращается к предварительно вычисленным агрегатам.Сценарий использования:Создание представления для быстрого рендеринга графиков анализа активности, где разрешение 1 секунда избыточно (downsampling).SQLCREATE MATERIALIZED VIEW activity_samples_1min
WITH (timescaledb.continuous) AS
SELECT
    activity_id,
    time_bucket('1 minute', time) AS bucket,
    AVG(power) AS avg_power,
    MAX(heart_rate) AS max_hr,
    AVG(speed) AS avg_speed,
    MAX(elevation) - MIN(elevation) as elevation_gain
FROM sensor_telemetry
GROUP BY activity_id, bucket;

-- Политика обновления
SELECT add_continuous_aggregate_policy('activity_samples_1min',
    start_offset => INTERVAL '3 days',
    end_offset => INTERVAL '1 hour',
    schedule_interval => INTERVAL '1 hour');
Этот подход гарантирует, что запросы аналитики будут выполняться за миллисекунды, независимо от объема исторических данных.52. Паттерны Моделирования Физиологических МетрикBioLight, как аналитическая платформа, должна не просто хранить сырые данные, но и эффективно работать с производными метриками, которые зависят от контекста (например, пороговых значений спортсмена на момент тренировки).2.1. W' Balance (Анаэробная Батарея): Алгоритмическая Сложность и ХранениеМодель критической мощности (Critical Power - CP) разделяет выработку энергии на аэробную (устойчивую, CP) и анаэробную (исчерпаемую, W'). W' Balance (W'BAL) — это динамическая метрика, показывающая остаток анаэробной емкости в джоулях в каждый момент времени $t$.Математическая модель:Существует два основных алгоритма расчета:Интегральная модель (Skiba 1): Требует вычисления интеграла свертки по всей истории тренировки до точки $t$. Это вычислительно дорого ($O(N^2)$ в наивной реализации).Дифференциальная модель (Skiba 2 / Froncioni): Вычисляет состояние в момент $t$ на основе состояния в момент $t-1$. Это более эффективно для потоковой обработки ($O(N)$).Формула дифференциального восстановления при $P < CP$:$$W'_{bal}(t) = W'_{bal}(t-1) + (CP - P(t)) \cdot \frac{W' - W'_{bal}(t-1)}{W'} \cdot \Delta t$$При $P > CP$, $W'_{bal}$ уменьшается линейно: $W'_{bal}(t) = W'_{bal}(t-1) - (P(t) - CP) \Delta t$.Стратегия Хранения:Главная проблема W'BAL заключается в том, что она зависит от значения CP. Поскольку CP спортсмена меняется в течение сезона, пересчет CP задним числом требует пересчета всей серии W'BAL для всех активностей.Рекомендация: Не хранить временной ряд W'BAL в базе данных на постоянной основе. Это избыточно. Вместо этого:Хранить параметры модели (CP и W') в истории настроек атлета (см. Раздел 3).Вычислять W'BAL "на лету" (On-the-fly) при загрузке активности или на клиенте (JavaScript/WASM), используя сохраненные параметры.Для аналитических целей сохранять только агрегаты в метаданных активности: min_w_bal (минимальный остаток), w_bal_depletion_rate (скорость истощения).Если требования к производительности чтения критичны (например, мгновенное отображение на мобильном), можно кэшировать рассчитанный массив W'BAL в бинарном формате (например, Protocol Buffers или простой массив float) в BLOB-хранилище (S3) или отдельной колонке bytea, связанной с активностью, но не как строки в sensor_telemetry.82.2. Вариабельность Сердечного Ритма (HRV)HRV требует особого подхода, так как данные интервалов R-R (время между ударами сердца) поступают нерегулярно и не привязаны к жесткой секундной сетке.Сырые данные (RR Intervals): Хранить в отдельной таблице rr_intervals, связанной с активностью. Так как эти данные нужны только для глубокого анализа (поиск аритмий, DFA-a1 для порогов), их можно хранить массивами в PostgreSQL (INTEGER), что значительно экономит место по сравнению с хранением "одна строка на удар".Агрегаты (Wellness Metrics): Ежедневные измерения (например, утренний HRV от Oura или Garmin) должны храниться в таблице daily_metrics. Ключевые поля: rmssd (Root Mean Square of Successive Differences), sdnn, readiness_score. Эти данные коррелируют с тренировочной нагрузкой для оценки восстановления.2.3. Виртуальная Мощность (Virtual Power)Для пользователей без измерителей мощности BioLight должен рассчитывать "Virtual Power" на основе скорости и кривой сопротивления тренажера.Схема хранения кривых:Необходима таблица power_curves, содержащая коэффициенты полинома для различных моделей тренажеров.$$Power = A + B \cdot Speed + C \cdot Speed^2 + D \cdot Speed^3$$Таблица 2. Схема equipment_power_curvesПолеТипОписаниеtrainer_model_idINTEGERID модели тренажера.coefficientsFLOATМассив коэффициентов.source_urlTEXTСсылка на источник данных (производитель).При обработке активности, если обнаружен только датчик скорости, система ищет профиль оборудования пользователя, извлекает коэффициенты и генерирует серию данных мощности, которая сохраняется в sensor_telemetry (возможно, с флагом is_virtual=true).3. Модели Данных для Периодизации и Управления НагрузкойСовременная спортивная наука опирается на отслеживание динамики физиологических параметров. Критическая ошибка многих систем — хранение параметров (FTP, Вес, Пульс ПАНО) как статических полей в профиле пользователя. В реальности атлет меняется: FTP растет весной и падает в межсезонье. Для корректного расчета исторической нагрузки (TSS) необходимо использовать паттерн Slowly Changing Dimensions (SCD) Type 2.3.1. Историзация Параметров Атлета (SCD Тип 2)Необходимо создать таблицу athlete_settings_history, которая версионирует физиологические параметры. Каждая запись имеет период валидности (valid_from, valid_to).SQLCREATE TABLE athlete_settings_history (
    id              SERIAL PRIMARY KEY,
    athlete_id      UUID NOT NULL REFERENCES athletes(id),
    valid_from      TIMESTAMPTZ NOT NULL,
    valid_to        TIMESTAMPTZ, -- NULL означает "текущая активная запись"
    
    -- Физиологические параметры
    ftp             INTEGER CHECK (ftp > 0),
    critical_power  INTEGER,
    w_prime         INTEGER,     -- Дж
    weight_kg       NUMERIC(5,2),
    hr_max          INTEGER,
    hr_lthr         INTEGER,     -- Порог лактата
    
    -- Ограничение для предотвращения перекрытия интервалов времени для одного атлета
    EXCLUDE USING GIST (
        athlete_id WITH =,
        tstzrange(valid_from, valid_to) WITH &&
    )
);
Логика работы:При загрузке новой активности от 15 июня 2023 года, система делает запрос к этой таблице, чтобы найти запись, где valid_from <= '2023-06-15' AND (valid_to > '2023-06-15' OR valid_to IS NULL). Найденное значение FTP используется для расчета TSS (Training Stress Score) именно этой тренировки. Это обеспечивает историческую точность данных: изменение FTP сегодня не должно пересчитывать нагрузку за прошлый год.103.2. График Управления Эффективностью (PMC)Для реализации модели Impulse-Response (Banister Model), используемой в TrainingPeaks (CTL, ATL, TSB), необходимо хранить ежедневно агрегированные метрики.Таблица athlete_daily_performance:Эта таблица заполняется фоновым процессом или триггером.ctl (Fitness): Экспоненциально взвешенное скользящее среднее (EWMA) TSS за 42 дня.atl (Fatigue): EWMA TSS за 7 дней.tsb (Form): ctl - atl.Расчет требует строго последовательной обработки данных. Нельзя рассчитать CTL на сегодня, не зная CTL на вчера.$$CTL_{today} = CTL_{yesterday} + (TSS_{today} - CTL_{yesterday}) \cdot (1 - e^{-1/42})$$Схема данных:ПолеТипОписаниеdateDATEДата метрики.athlete_idUUIDID атлета.total_tssREALСумма TSS всех тренировок за день.ctlREALChronic Training Load.atlREALAcute Training Load.tsbREALTraining Stress Balance.При добавлении/изменении исторической тренировки необходимо инициировать пересчет ("re-flow") всех последующих значений CTL/ATL/TSB в этой таблице.133.3. Структурированные Тренировки (Planned Workouts)Для хранения плановых тренировок ("Интервалы 5x5 мин на 110% FTP") рекомендуется использовать формат JSONB, который легко транслируется в форматы устройств (.FIT,.ZWO). Жесткая реляционная схема для структуры тренировки (таблицы steps, repeats) часто избыточна и сложна в поддержке вложенности.4. Интеграция с Внешними Экосистемами: Garmin и StravaЭффективная агрегация данных — ключевая функция BioLight. Работа с проприетарными форматами и API требует надежных пайплайнов обработки.4.1. Пайплайн Обработки FIT Файлов (Garmin)Формат FIT (Flexible and Interoperable Data Transfer) — это бинарный стандарт де-факто в индустрии. Он компактен, но сложен для парсинга.Анатомия FIT файла:Файл состоит из заголовка, блоков определений (Definition Messages) и блоков данных (Data Messages). Сложность заключается в том, что "схема" данных передается внутри самого файла. Сообщение record может содержать поля timestamp и heart_rate в одном файле, и timestamp, power, left_right_balance в другом.16Архитектура Интеграции:Ingestion: Пользователь загружает файл или Webhook от Garmin Health API передает ссылку.Staging: Файл сохраняется "как есть" в объектном хранилище (S3/MinIO). Это "Source of Truth". Никогда не удаляйте исходные файлы — парсеры улучшаются, и может потребоваться повторная обработка.Parsing (Worker): Асинхронный воркер (на Python с использованием fitdecode или SDK) разбирает файл.Сообщения типа session -> Таблица activities (итоговое время, калории, TSS от устройства).Сообщения типа lap -> Таблица laps (отсечки кругов).Сообщения типа record -> Пакетная вставка (Batch Insert) в sensor_telemetry. Здесь происходит маппинг полей FIT на колонки БД. Неизвестные поля (developer fields) сериализуются в JSONB.4.2. Интеграция со Strava APIStrava API предоставляет данные в формате JSON, но имеет строгие лимиты (Rate Limits: 100 запросов за 15 минут).Стратегия Синхронизации:Webhook-First: Использовать подписку на вебхуки Strava (activity.create). При получении события ID активности ставится в очередь (RabbitMQ/Redis).Отложенная обработка: Воркер забирает задачу из очереди, проверяет доступные лимиты и запрашивает детали активности (GET /activities/{id}).Streams API: Для получения временных рядов (потоков) требуется отдельный запрос (GET /activities/{id}/streams). Важно нормализовать эти данные к единому формату, совместимому с данными из FIT файлов, перед записью в sensor_telemetry. Например, Strava может возвращать массив [time, watts], который нужно развернуть в строки с абсолютными timestamp.5. Архитектура Real-Time АналитикиСценарий использования "Live Coaching" предполагает, что тренер видит данные спортсмена в реальном времени (например, во время удаленного теста FTP). Это требует перехода от пакетной обработки (Batch) к потоковой (Stream).5.1. Протокол MQTT для Интернета Вещей (IoT)HTTP не подходит для потоковой передачи телеметрии с сенсоров из-за оверхеда на установку соединения и заголовки. Рекомендуется использовать MQTT — легковесный протокол публикация/подписка.Дизайн Топиков MQTT:Правильная иерархия топиков критична для безопасности и маршрутизации.19Шаблон: biolight/{environment}/{athlete_id}/{device_id}/{metric_type}Пример: biolight/prod/user_550e8400/polar_h10/heartrateЭто позволяет тренеру подписаться на biolight/prod/user_550e8400/# и получать все данные конкретного атлета.Брокер сообщений: Использование брокера, такого как EMQX или Mosquitto. Брокер должен поддерживать аутентификацию устройств и ACL (списки контроля доступа), чтобы один атлет не мог писать в топик другого.215.2. Потоковая Обработка и Stateful CalculationsРасчет метрик типа W'BAL в реальном времени является stateful задачей. Чтобы рассчитать $W'_{bal}(t)$, нужно знать $W'_{bal}(t-1)$ и $CP$ атлета.Архитектура Потока:Ingest: Мобильное приложение атлета читает Bluetooth-сенсоры и публикует JSON в MQTT: {"ts": 162500000, "pwr": 300}.Stream Processor: Сервис (например, на Python Faust или Apache Flink) слушает топик MQTT.Управление Состоянием (State Store): Процессор использует Redis для хранения контекста ("состояния") сессии:Ключ: session_state:{athlete_id}Значение: { "cp": 250, "w_prime": 20000, "current_w_bal": 18500, "last_ts": 162499999 }Compute: При получении нового пакета процессор берет данные из Redis, применяет дифференциальную формулу W'BAL, обновляет состояние в Redis и публикует результат в новый топик biolight/derived/{athlete_id}/wbal.Delivery: Backend пересылает данные из производного топика в WebSockets для отображения на фронтенде тренера с минимальной задержкой.Persistence: Отдельный сервис "Cold Storage Consumer" накапливает данные из MQTT и пакетами (batch) пишет их в TimescaleDB для истории, не блокируя горячий путь данных.226. Ресурсы для Валидации и Тестирования АлгоритмовДля верификации корректности расчетов (особенно сложных моделей CP и W') необходимо использовать эталонные данные ("Ground Truth").6.1. GoldenCheetah OpenDataЭто крупнейший открытый репозиторий данных циклических видов спорта.Состав: Более 700,000 активностей от тысяч атлетов.Формат: Данные доступны в виде CSV файлов и JSON структур. Содержит как сырые данные, так и рассчитанные метрики GoldenCheetah, что позволяет использовать их как эталон для unit-тестов ваших алгоритмов.Применение: Скачайте подмножество данных. Реализуйте свой алгоритм расчета CP. Сравните ваш результат с метрикой cp_history из датасета. Расхождения помогут найти ошибки в реализации.246.2. Mendeley Data (Time Trial Datasets)Научные датасеты, полученные в контролируемых лабораторных условиях (например, 20км Time Trial).Ценность: В отличие от "диких" данных GoldenCheetah, здесь минимизированы шумы (ошибки GPS, сбои датчиков). Идеально для калибровки базовой физической модели.266.3. Синтетические ДатасетыДля проверки граничных условий (edge cases) рекомендуется создать генератор синтетических FIT-файлов.Сценарии: Идеальная рампа (постепенное повышение мощности до отказа), интервалы с "дырами" (потеря сигнала), данные с аномальными пиками (спайками). Тестирование на таких данных гарантирует, что система не выдаст абсурдный "новый рекорд по мощности" из-за сбоя датчика.ЗаключениеПредложенная архитектура BioLight представляет собой надежную платформу промышленного уровня. Использование PostgreSQL/TimescaleDB решает дилемму хранения временных рядов без фрагментации стека. Внедрение SCD Type 2 обеспечивает научную корректность исторического анализа, что критически важно для профессионального спорта. Комбинация MQTT и потоковой обработки через Redis открывает возможности для функционала "живого" тренерства, создавая конкурентное преимущество перед системами, работающими только в режиме пост-анализа. Реализация этой спецификации создаст фундамент, способный выдержать рост от пилотного запуска до высоконагруженной SaaS-платформы.